{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kQOMLVc6MnJ_FI8SPK6REOKBZ4B-_TKO",
      "authorship_tag": "ABX9TyNotdyah4ky7igEOYJT4cFC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LNhart/automl_metalearning/blob/main/xgboost_metalearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas==1.3.5\n",
        "!pip install xgboost==1.5.1\n",
        "!pip install openml==0.12.2\n",
        "!pip install seaborn==0.12.2"
      ],
      "metadata": {
        "id": "3GvcGTqcMFGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "8At0yHt2fxfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "utility functions"
      ],
      "metadata": {
        "id": "nooZvGurKPhe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7TOfmKvtA9Zf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "test_ids = [\n",
        "    16, 22, 31, 2074, 2079, 3493, 3907, 3913, 9950, 9952, 9971, 10106, 14954, 14970, 146212,\n",
        "    146825, 167119, 167125, 168332, 168336\n",
        "]\n",
        "\n",
        "meta_feature_names = [\n",
        "    \"data_id\", \"name\", \"status\", \"MajorityClassSize\", \"MaxNominalAttDistinctValues\",\n",
        "    \"MinorityClassSize\", \"NumberOfClasses\", \"NumberOfFeatures\", \"NumberOfInstances\",\n",
        "    \"NumberOfInstancesWithMissingValues\", \"NumberOfMissingValues\", \"NumberOfNumericFeatures\",\n",
        "    \"NumberOfSymbolicFeatures\"\n",
        "]\n",
        "\n",
        "default_config = {\n",
        "    \"n_estimators\": 464,  # num_rounds\n",
        "    \"eta\": 0.0082,\n",
        "    \"subsample\": 0.982,\n",
        "    \"max_depth\": 11,\n",
        "    \"min_child_weight\": 3.30,\n",
        "    \"colsample_bytree\": 0.975,\n",
        "    \"colsample_bylevel\": 0.9,\n",
        "    \"lambda\": 0.06068,\n",
        "    \"alpha\": 0.00235,\n",
        "    \"gamma\": 0\n",
        "}\n",
        "\n",
        "use_gpu = True\n",
        "silent = True\n",
        "\n",
        "def get_hyperparameter_list() -> List[str]:\n",
        "    return list(default_config.keys())\n",
        "\n",
        "def get_hyperparameter_data_list() -> List[str]:\n",
        "    config_list = get_hyperparameter_list()\n",
        "    config_list.remove(\"n_estimators\")\n",
        "    config_list.append(\"num_round\")\n",
        "    return config_list\n",
        "\n",
        "def get_metafeature_list() -> List[str]:\n",
        "    return meta_feature_names\n",
        "\n",
        "def load_data_from_path(path_to_files: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Loads the meta files from disk and returns them as data frames\"\"\"\n",
        "    files_to_load = dict(\n",
        "        features=\"features.csv\",\n",
        "        meta_features=\"xgboost_meta_data.csv\"\n",
        "    )\n",
        "    meta_features = pd.read_csv(os.path.join(path_to_files, files_to_load[\"features\"]))\n",
        "    meta_data = pd.read_csv(os.path.join(path_to_files, files_to_load[\"meta_features\"]))\n",
        "    return meta_features, meta_data\n",
        "\n",
        "def _get_preprocessor(categoricals, continuous):\n",
        "    \"\"\"Preprocessing\"\"\"\n",
        "    preprocessor = make_pipeline(\n",
        "        ColumnTransformer([\n",
        "            (\n",
        "                \"cat\",\n",
        "                make_pipeline(\n",
        "                    SimpleImputer(strategy=\"most_frequent\"),\n",
        "                    OneHotEncoder(handle_unknown=\"ignore\")\n",
        "                ),\n",
        "                categoricals.tolist(),\n",
        "            ),\n",
        "            (\n",
        "                \"cont\",\n",
        "                make_pipeline(\n",
        "                    SimpleImputer(strategy=\"median\")\n",
        "                ),\n",
        "                continuous.tolist(),\n",
        "            )\n",
        "        ])\n",
        "    )\n",
        "    return preprocessor\n",
        "\n",
        "def get_task_metafeatures(task_id: int, meta_feature_names: List[str]) -> Dict:\n",
        "    \"\"\"Get meta features from an OpenML task based on its task id\"\"\"\n",
        "    task = openml.tasks.get_task(task_id)\n",
        "    features = openml.datasets.list_datasets(data_id=[task.dataset_id])[task.dataset_id]\n",
        "    features[\"data_id\"] = features[\"did\"]\n",
        "\n",
        "    for feature in set(features.keys()) - set(meta_feature_names):\n",
        "        features.pop(feature)\n",
        "\n",
        "    return features\n",
        "\n",
        "def _convert_labels(labels):\n",
        "    \"\"\"Converts boolean labels (if exists) to strings\"\"\"\n",
        "    label_types = list(map(lambda x: isinstance(x, bool), labels))\n",
        "    if np.all(label_types):\n",
        "        _labels = list(map(lambda x: str(x), labels))\n",
        "        if isinstance(labels, pd.Series):\n",
        "            labels = pd.Series(_labels, index=labels.index)\n",
        "        elif isinstance(labels, np.array):\n",
        "            labels = np.array(labels)\n",
        "    return labels\n",
        "\n",
        "def load_test_data(task_id: int) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Fetches data from OpenML, converts data types, to yield train-test numpy arrays\"\"\"\n",
        "    task = openml.tasks.get_task(task_id, download_data=False)\n",
        "    nclasses = len(task.class_labels)\n",
        "    dataset = openml.datasets.get_dataset(task.dataset_id, download_data=False)\n",
        "    X, y, categorical_ind, feature_names = dataset.get_data(target=task.target_name, dataset_format=\"dataframe\")\n",
        "\n",
        "    categorical_ind = np.array(categorical_ind)\n",
        "    (cat_idx,) = np.where(categorical_ind)\n",
        "    (cont_idx,) = np.where(~categorical_ind)\n",
        "\n",
        "    # splitting dataset into train and test (10% test)\n",
        "    # train-test split is fixed for a task and its associated dataset (from OpenML)\n",
        "    train_idx, test_idx = task.get_train_test_split_indices()  # we only use the first of the 10 CV folds\n",
        "\n",
        "    train_x = X.iloc[train_idx]\n",
        "    train_y = y.iloc[train_idx]\n",
        "    test_x = X.iloc[test_idx]\n",
        "    test_y = y.iloc[test_idx]\n",
        "\n",
        "    preprocessor = _get_preprocessor(cat_idx, cont_idx)\n",
        "\n",
        "    # preprocessor fit only on the training set\n",
        "    train_x = preprocessor.fit_transform(train_x)\n",
        "    test_x = preprocessor.transform(test_x)\n",
        "\n",
        "    # converting bool labels\n",
        "    train_y = _convert_labels(train_y)\n",
        "    test_y = _convert_labels(test_y)\n",
        "\n",
        "    # encoding labels\n",
        "    le = LabelEncoder()\n",
        "    le.fit(np.unique(train_y))\n",
        "    train_y = le.transform(train_y)\n",
        "    test_y = le.transform(test_y)\n",
        "\n",
        "    return train_x, train_y, test_x, test_y, nclasses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline"
      ],
      "metadata": {
        "id": "kFw3NK1wMzaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#from utils import get_task_metafeatures, load_test_data, meta_feature_names, \\\n",
        "#    default_config, test_ids\n",
        "\n",
        "class XGBoostTest:\n",
        "    \"\"\"Set seed, get train-test data and meta features of task_id\"\"\"\n",
        "    def __init__(self, task_id: int, meta_feature_names: list, seed: int = 12345):\n",
        "        self.seed = seed\n",
        "        self.task_id = task_id\n",
        "        self.train_x, self.train_y, self.test_x, self.test_y, self.nclasses = load_test_data(task_id)\n",
        "        self.meta_features = get_task_metafeatures(task_id, meta_feature_names)\n",
        "\n",
        "    \"\"\"Initialize the xgboost learner based on a hyperparameter configuration\"\"\"\n",
        "    def init_model(self, config: dict, seed: int = None):\n",
        "        rng = np.random.RandomState(self.seed) if seed is None else np.random.RandomState(seed)\n",
        "        extra_args = dict(random_state=rng, eval_metric=roc_auc_score)\n",
        "        if self.nclasses > 2:\n",
        "            extra_args[\"objective\"] = \"multi:softprob\"\n",
        "            extra_args.update({\"num_class\": self.nclasses})\n",
        "\n",
        "        if use_gpu:\n",
        "          config = config.copy()\n",
        "          config[\"tree_method\"] = \"gpu_hist\"\n",
        "\n",
        "        if silent:\n",
        "          config = config.copy()\n",
        "          config[\"verbosity\"] = 0\n",
        "\n",
        "        #print(default_config)\n",
        "        #print(config)\n",
        "\n",
        "        model = xgb.XGBClassifier(\n",
        "            **config,\n",
        "            **extra_args\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    \"\"\"\n",
        "    Evaluate the xbgoost learner by first initializing the model based on a hyperparameter configuration,\n",
        "    train on train set and evaluate on test set based on AUC\n",
        "    \"\"\"\n",
        "    def evaluate(self, config: dict, seed: int=None):\n",
        "        model = self.init_model(config, seed)\n",
        "        train_start = time.time()\n",
        "        model.fit(self.train_x, self.train_y)\n",
        "        timetrain = time.time() - train_start\n",
        "        prediction_prob = model.predict_proba(self.test_x)\n",
        "        if self.nclasses == 2:\n",
        "            # handling binary classification\n",
        "            prediction_prob = prediction_prob[:, 1]\n",
        "        auc = roc_auc_score(self.test_y, prediction_prob, multi_class=\"ovr\")\n",
        "        return auc, timetrain"
      ],
      "metadata": {
        "id": "v8wvjfdsMt3A"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data"
      ],
      "metadata": {
        "id": "-RVuUg8EiWZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in this case, datasets were put into my google drive in a folder called \"xgboost--metalearning\"\n",
        "\n",
        "tasks_meta, configs_meta = load_data_from_path(\"/content/drive/MyDrive/xgboost--metalearning\")"
      ],
      "metadata": {
        "id": "6nTBXLJ6jWjL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimating importance of hyperparameters"
      ],
      "metadata": {
        "id": "zvUqcSDg406A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def feature_importance_mdi(data_id: int, cols: List[str]):\n",
        "  '''calculates feature importance based on random forest'''\n",
        "  config_meta_task = configs_meta[configs_meta[\"data_id\"] == data_id]\n",
        "  X = config_meta_task[cols]\n",
        "  y = config_meta_task[\"auc\"]\n",
        "\n",
        "  rfr = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=0)\n",
        "  rfr.fit(X, y)\n",
        "  feature_importances = rfr.feature_importances_\n",
        "\n",
        "  return feature_importances\n",
        "\n",
        "def feature_importance_lr_coef(data_id: int, cols: List[str]):\n",
        "  '''calculates feature importance based on coeficients in linear regression model'''\n",
        "  config_meta_task = configs_meta[configs_meta[\"data_id\"] == data_id]\n",
        "  X = config_meta_task[cols]\n",
        "  y = config_meta_task[\"auc\"]\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "  lr = LinearRegression()\n",
        "  lr.fit(X, y)\n",
        "  feature_coefs = lr.coef_\n",
        "  \n",
        "  return feature_coefs\n",
        "\n",
        "cols = get_hyperparameter_list()\n",
        "cols.remove(\"n_estimators\")\n",
        "cols.append(\"num_round\")\n",
        "\n",
        "data_ids = configs_meta[\"data_id\"].unique()\n",
        "results_mdi = [feature_importance_mdi(id, cols) for id in data_ids]\n",
        "results_rc = [feature_importance_lr_coef(id, cols) for id in data_ids]"
      ],
      "metadata": {
        "id": "rjISPhjDmDV8"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import boxplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f_mdi = pd.DataFrame(data=results_mdi, columns=cols, index = data_ids)\n",
        "\n",
        "plt.figure(figsize=(20, 12))\n",
        "plt.xticks(fontsize=11)\n",
        "\n",
        "boxplot(data=pd.melt(df_mdi), x=\"variable\", y=\"value\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "Emr3UwmOcfFi",
        "outputId": "bb377cba-a4bd-4a52-b799-16f611dd1f28"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='variable', ylabel='value'>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x864 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "cols = get_hyperparameter_list()\n",
        "cols.remove(\"n_estimators\")\n",
        "cols.append(\"num_round\")\n",
        "\n",
        "# standardizing the data\n",
        "configs_meta_standardized = pd.DataFrame(data=scaler.fit_transform(configs_meta[cols]), columns=cols)\n",
        "\n",
        "configs_meta_standardized[\"data_id\"] = configs_meta[\"data_id\"]\n",
        "configs_meta_standardized[\"auc\"] = configs_meta[\"auc\"]\n",
        "\n",
        "# getting the top config for each group\n",
        "configs_top = configs_meta_standardized.sort_values(by=[\"data_id\", \"auc\"], \n",
        "                                                    ascending=[True, False]).groupby(\"data_id\").nth(1)\n",
        "\n",
        "configs_top = configs_top.drop(columns=[\"auc\"])"
      ],
      "metadata": {
        "id": "UwObNeV5qJJJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import boxplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plot of the variance in top values for given hyperparameters\n",
        "plt.figure(figsize=(20, 12))\n",
        "plt.xticks(fontsize=11)\n",
        "\n",
        "boxplot(data=pd.melt(configs_top), x=\"variable\", y=\"value\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "N2tim_Iux_Nx",
        "outputId": "ecf03bb6-8d24-4cdd-c73a-43886b29bba9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='variable', ylabel='value'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# only clustering based on these hyperparams\n",
        "relevant_hyperparams = [\"num_round\", \"eta\", \"subsample\", \"max_depth\", \"min_child_weight\", \"colsample_bytree\"]\n",
        "\n",
        "hyperparams = configs_meta[relevant_hyperparams]\n",
        "hyperparams = StandardScaler().fit_transform(hyperparams)\n",
        "\n",
        "df_clustering_configs = pd.DataFrame(hyperparams, columns=relevant_hyperparams)\n",
        "df_clustering_configs[\"data_id\"] = configs_meta[\"data_id\"]\n",
        "df_clustering_configs[\"auc\"] = configs_meta[\"auc\"]\n",
        "\n",
        "# selecting top 20 configs per task\n",
        "df_clustering_configs_top20 =  df_clustering_configs.sort_values(by=[\"data_id\", \"auc\"], \n",
        "                                                    ascending=[True, False]).groupby(\"data_id\").head(20)\n",
        "df_clustering_configs_top20 = df_clustering_configs_top20.drop(columns=[\"data_id\", \"auc\"])\n",
        "df_clustering_configs_top20 = df_clustering_configs_top20.drop_duplicates()\n",
        "\n",
        "# clustering into 25 clusters\n",
        "kmeans = KMeans(n_clusters=25, random_state=0, init=\"k-means++\").fit(df_clustering_configs_top20)\n",
        "df_clustering_configs_top20[\"cluster\"] = kmeans.labels_\n",
        "\n",
        "df_clustering_configs_top20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "Rf-ygA7IBcB3",
        "outputId": "260099d6-acfb-4620-c4dc-00dde49160cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         num_round       eta  subsample  max_depth  min_child_weight  \\\n",
              "1584222   2.419637  2.226816  -0.602792  -0.913329         -0.046683   \n",
              "1584271  -0.261079  0.917630   0.846709   1.268339         -0.047239   \n",
              "1584809  -0.105601 -0.596334   1.738073   1.486505         -0.047367   \n",
              "1584892   0.881941  3.788776   0.586777   0.177505         -0.048494   \n",
              "1584908   0.101134 -0.152861   1.520750   1.486505         -0.046305   \n",
              "...            ...       ...        ...        ...               ...   \n",
              "1373503   1.191189 -0.438611   0.907455   0.613838         -0.016473   \n",
              "1227744  -0.303792 -0.378343  -0.236468  -0.695162         -0.040970   \n",
              "1247584  -0.449019  1.698016   0.141722   0.177505         -0.030698   \n",
              "1233050  -0.500276 -0.447740   0.889890   1.268339         -0.040242   \n",
              "1240943  -0.566909  2.809389   1.641316  -0.040662         -0.044212   \n",
              "\n",
              "         colsample_bytree  cluster  \n",
              "1584222         -0.500052       22  \n",
              "1584271          1.214615        2  \n",
              "1584809          1.372577        2  \n",
              "1584892          1.683623       18  \n",
              "1584908         -0.636191        9  \n",
              "...                   ...      ...  \n",
              "1373503         -0.437212       13  \n",
              "1227744         -0.030301        5  \n",
              "1247584          1.639710       11  \n",
              "1233050          0.749812        2  \n",
              "1240943          1.223086       18  \n",
              "\n",
              "[853 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f560d408-8065-4d63-b119-6d9f7c5eb60b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_round</th>\n",
              "      <th>eta</th>\n",
              "      <th>subsample</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_child_weight</th>\n",
              "      <th>colsample_bytree</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1584222</th>\n",
              "      <td>2.419637</td>\n",
              "      <td>2.226816</td>\n",
              "      <td>-0.602792</td>\n",
              "      <td>-0.913329</td>\n",
              "      <td>-0.046683</td>\n",
              "      <td>-0.500052</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1584271</th>\n",
              "      <td>-0.261079</td>\n",
              "      <td>0.917630</td>\n",
              "      <td>0.846709</td>\n",
              "      <td>1.268339</td>\n",
              "      <td>-0.047239</td>\n",
              "      <td>1.214615</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1584809</th>\n",
              "      <td>-0.105601</td>\n",
              "      <td>-0.596334</td>\n",
              "      <td>1.738073</td>\n",
              "      <td>1.486505</td>\n",
              "      <td>-0.047367</td>\n",
              "      <td>1.372577</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1584892</th>\n",
              "      <td>0.881941</td>\n",
              "      <td>3.788776</td>\n",
              "      <td>0.586777</td>\n",
              "      <td>0.177505</td>\n",
              "      <td>-0.048494</td>\n",
              "      <td>1.683623</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1584908</th>\n",
              "      <td>0.101134</td>\n",
              "      <td>-0.152861</td>\n",
              "      <td>1.520750</td>\n",
              "      <td>1.486505</td>\n",
              "      <td>-0.046305</td>\n",
              "      <td>-0.636191</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1373503</th>\n",
              "      <td>1.191189</td>\n",
              "      <td>-0.438611</td>\n",
              "      <td>0.907455</td>\n",
              "      <td>0.613838</td>\n",
              "      <td>-0.016473</td>\n",
              "      <td>-0.437212</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1227744</th>\n",
              "      <td>-0.303792</td>\n",
              "      <td>-0.378343</td>\n",
              "      <td>-0.236468</td>\n",
              "      <td>-0.695162</td>\n",
              "      <td>-0.040970</td>\n",
              "      <td>-0.030301</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1247584</th>\n",
              "      <td>-0.449019</td>\n",
              "      <td>1.698016</td>\n",
              "      <td>0.141722</td>\n",
              "      <td>0.177505</td>\n",
              "      <td>-0.030698</td>\n",
              "      <td>1.639710</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233050</th>\n",
              "      <td>-0.500276</td>\n",
              "      <td>-0.447740</td>\n",
              "      <td>0.889890</td>\n",
              "      <td>1.268339</td>\n",
              "      <td>-0.040242</td>\n",
              "      <td>0.749812</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1240943</th>\n",
              "      <td>-0.566909</td>\n",
              "      <td>2.809389</td>\n",
              "      <td>1.641316</td>\n",
              "      <td>-0.040662</td>\n",
              "      <td>-0.044212</td>\n",
              "      <td>1.223086</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>853 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f560d408-8065-4d63-b119-6d9f7c5eb60b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f560d408-8065-4d63-b119-6d9f7c5eb60b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f560d408-8065-4d63-b119-6d9f7c5eb60b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_candidate_configs_median(clusters: pd.Series, config_meta: pd.DataFrame):\n",
        "  ''' creates one candidate per cluster with median config values within each cluster'''\n",
        "  config_meta[\"cluster\"] = clusters\n",
        "  candidates = config_meta.groupby(\"cluster\").median()\n",
        "  candidates = candidates.drop(columns=[\"data_id\", \"repl\", \"timetrain\", \"auc\", \"task_id\"])\n",
        "  candidates[\"num_round\"] = candidates[\"num_round\"].astype(int)\n",
        "  candidates[\"max_depth\"] = candidates[\"max_depth\"].astype(int)\n",
        "  return candidates\n",
        "\n",
        "median_candidates = generate_candidate_configs_median(df_clustering_configs_top20[\"cluster\"], configs_meta)\n",
        "\n",
        "# writes candidates to csv to allow loading them without rerunning prior steps\n",
        "median_candidates.to_csv(\"candidates.csv\", index_label=\"cluster\")"
      ],
      "metadata": {
        "id": "PoQhAH_Lr5X6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "median_candidates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "9PyZO_p9OaHB",
        "outputId": "e31d9edf-cdf2-4448-a15d-cb3ae8cd7612"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         num_round       eta     gamma    lambda     alpha  subsample  \\\n",
              "cluster                                                                 \n",
              "0.0          166.0  0.071020  0.022067  0.135410  0.053157   0.413686   \n",
              "1.0         1392.5  0.034815  0.002679  0.152595  0.046335   0.602411   \n",
              "2.0          173.0  0.041437  0.026897  0.197935  0.038136   0.826596   \n",
              "3.0          289.0  0.466464  0.001009  0.207158  0.035647   0.370796   \n",
              "4.0          165.0  0.739480  0.011468  0.538858  0.215100   0.723950   \n",
              "5.0          104.5  0.049899  0.013476  0.049453  0.101912   0.422882   \n",
              "6.0         2971.0  0.054328  0.003280  0.328136  0.031793   0.757398   \n",
              "7.0          389.0  0.024508  0.005148  0.139992  0.070846   0.561667   \n",
              "8.0         1552.0  0.022405  0.000917  1.590720  0.096197   0.625077   \n",
              "9.0          196.0  0.080499  0.001612  0.086150  0.028965   0.725828   \n",
              "10.0         293.0  0.455810  0.005761  0.403477  0.288837   0.599897   \n",
              "11.0          55.0  0.452886  0.021100  0.091779  0.429795   0.874718   \n",
              "12.0        5137.0  0.144903  0.001511  0.225318  1.150830   0.743634   \n",
              "13.0        1188.5  0.032400  0.012641  0.309555  0.151353   0.928319   \n",
              "14.0         272.5  0.275205  0.047424  0.136065  0.076714   0.799798   \n",
              "15.0         262.0  0.042639  0.014007  0.140290  0.062701   0.746251   \n",
              "16.0         165.0  0.082837  0.020973  0.080026  0.030628   0.868877   \n",
              "17.0        1339.5  0.034069  0.005725  0.376560  0.064059   0.540126   \n",
              "18.0         153.0  0.693929  0.053121  4.198730  0.018771   0.899400   \n",
              "19.0         622.0  0.358716  0.021738  0.070847  0.479492   0.381012   \n",
              "20.0         130.0  0.795394  0.004153  0.692878  0.056583   0.480324   \n",
              "21.0         220.5  0.067427  0.005642  0.142211  0.095997   0.261880   \n",
              "22.0        1231.0  0.624999  0.003042  1.114030  0.127632   0.739908   \n",
              "23.0        1112.0  0.060090  0.002159  0.125824  0.059589   0.470073   \n",
              "24.0        1366.0  0.041916  0.004067  0.483038  0.083931   0.888827   \n",
              "\n",
              "         max_depth  min_child_weight  colsample_bytree  colsample_bylevel  \n",
              "cluster                                                                    \n",
              "0.0            9.0          2.542185          0.282563           0.649248  \n",
              "1.0            4.0          3.168880          0.838539           0.568505  \n",
              "2.0           14.0          2.450420          0.760872           0.557491  \n",
              "3.0           13.0          4.599500          0.891617           0.489028  \n",
              "4.0            3.0          2.729570          0.700514           0.514345  \n",
              "5.0            4.0          2.479170          0.624448           0.519975  \n",
              "6.0            7.0         12.217100          0.655027           0.523727  \n",
              "7.0           13.0          3.000490          0.657172           0.465027  \n",
              "8.0           14.0          3.343410          0.266350           0.500222  \n",
              "9.0           14.0          2.909540          0.209120           0.579948  \n",
              "10.0          11.0          2.527590          0.376474           0.578379  \n",
              "11.0           7.5          3.218820          0.924980           0.606795  \n",
              "12.0           9.0          2.555050          0.233803           0.666969  \n",
              "13.0           9.0          4.023710          0.254911           0.463079  \n",
              "14.0           4.5          3.547130          0.227303           0.524093  \n",
              "15.0           6.0          2.689320          0.818483           0.535202  \n",
              "16.0          10.0          2.928495          0.463018           0.586307  \n",
              "17.0          11.0          3.218555          0.659938           0.548621  \n",
              "18.0          13.0          3.001680          0.734144           0.607351  \n",
              "19.0           4.0          2.536180          0.651744           0.426944  \n",
              "20.0           5.5          2.450475          0.154213           0.420525  \n",
              "21.0          10.0          2.030150          0.887042           0.564478  \n",
              "22.0          10.0          3.082620          0.423445           0.525608  \n",
              "23.0           5.0          2.354530          0.234480           0.375921  \n",
              "24.0          12.0          2.536365          0.729651           0.527142  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70c11b0f-0f9f-4d98-98c7-a39b6c41f2e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_round</th>\n",
              "      <th>eta</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "      <th>subsample</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_child_weight</th>\n",
              "      <th>colsample_bytree</th>\n",
              "      <th>colsample_bylevel</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>166.0</td>\n",
              "      <td>0.071020</td>\n",
              "      <td>0.022067</td>\n",
              "      <td>0.135410</td>\n",
              "      <td>0.053157</td>\n",
              "      <td>0.413686</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.542185</td>\n",
              "      <td>0.282563</td>\n",
              "      <td>0.649248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1392.5</td>\n",
              "      <td>0.034815</td>\n",
              "      <td>0.002679</td>\n",
              "      <td>0.152595</td>\n",
              "      <td>0.046335</td>\n",
              "      <td>0.602411</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.168880</td>\n",
              "      <td>0.838539</td>\n",
              "      <td>0.568505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>173.0</td>\n",
              "      <td>0.041437</td>\n",
              "      <td>0.026897</td>\n",
              "      <td>0.197935</td>\n",
              "      <td>0.038136</td>\n",
              "      <td>0.826596</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.450420</td>\n",
              "      <td>0.760872</td>\n",
              "      <td>0.557491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>289.0</td>\n",
              "      <td>0.466464</td>\n",
              "      <td>0.001009</td>\n",
              "      <td>0.207158</td>\n",
              "      <td>0.035647</td>\n",
              "      <td>0.370796</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.599500</td>\n",
              "      <td>0.891617</td>\n",
              "      <td>0.489028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>165.0</td>\n",
              "      <td>0.739480</td>\n",
              "      <td>0.011468</td>\n",
              "      <td>0.538858</td>\n",
              "      <td>0.215100</td>\n",
              "      <td>0.723950</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.729570</td>\n",
              "      <td>0.700514</td>\n",
              "      <td>0.514345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>104.5</td>\n",
              "      <td>0.049899</td>\n",
              "      <td>0.013476</td>\n",
              "      <td>0.049453</td>\n",
              "      <td>0.101912</td>\n",
              "      <td>0.422882</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.479170</td>\n",
              "      <td>0.624448</td>\n",
              "      <td>0.519975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>2971.0</td>\n",
              "      <td>0.054328</td>\n",
              "      <td>0.003280</td>\n",
              "      <td>0.328136</td>\n",
              "      <td>0.031793</td>\n",
              "      <td>0.757398</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.217100</td>\n",
              "      <td>0.655027</td>\n",
              "      <td>0.523727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>389.0</td>\n",
              "      <td>0.024508</td>\n",
              "      <td>0.005148</td>\n",
              "      <td>0.139992</td>\n",
              "      <td>0.070846</td>\n",
              "      <td>0.561667</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.000490</td>\n",
              "      <td>0.657172</td>\n",
              "      <td>0.465027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>1552.0</td>\n",
              "      <td>0.022405</td>\n",
              "      <td>0.000917</td>\n",
              "      <td>1.590720</td>\n",
              "      <td>0.096197</td>\n",
              "      <td>0.625077</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.343410</td>\n",
              "      <td>0.266350</td>\n",
              "      <td>0.500222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>196.0</td>\n",
              "      <td>0.080499</td>\n",
              "      <td>0.001612</td>\n",
              "      <td>0.086150</td>\n",
              "      <td>0.028965</td>\n",
              "      <td>0.725828</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.909540</td>\n",
              "      <td>0.209120</td>\n",
              "      <td>0.579948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>293.0</td>\n",
              "      <td>0.455810</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.403477</td>\n",
              "      <td>0.288837</td>\n",
              "      <td>0.599897</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.527590</td>\n",
              "      <td>0.376474</td>\n",
              "      <td>0.578379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11.0</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0.452886</td>\n",
              "      <td>0.021100</td>\n",
              "      <td>0.091779</td>\n",
              "      <td>0.429795</td>\n",
              "      <td>0.874718</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3.218820</td>\n",
              "      <td>0.924980</td>\n",
              "      <td>0.606795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12.0</th>\n",
              "      <td>5137.0</td>\n",
              "      <td>0.144903</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>0.225318</td>\n",
              "      <td>1.150830</td>\n",
              "      <td>0.743634</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.555050</td>\n",
              "      <td>0.233803</td>\n",
              "      <td>0.666969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13.0</th>\n",
              "      <td>1188.5</td>\n",
              "      <td>0.032400</td>\n",
              "      <td>0.012641</td>\n",
              "      <td>0.309555</td>\n",
              "      <td>0.151353</td>\n",
              "      <td>0.928319</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.023710</td>\n",
              "      <td>0.254911</td>\n",
              "      <td>0.463079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14.0</th>\n",
              "      <td>272.5</td>\n",
              "      <td>0.275205</td>\n",
              "      <td>0.047424</td>\n",
              "      <td>0.136065</td>\n",
              "      <td>0.076714</td>\n",
              "      <td>0.799798</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.547130</td>\n",
              "      <td>0.227303</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15.0</th>\n",
              "      <td>262.0</td>\n",
              "      <td>0.042639</td>\n",
              "      <td>0.014007</td>\n",
              "      <td>0.140290</td>\n",
              "      <td>0.062701</td>\n",
              "      <td>0.746251</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.689320</td>\n",
              "      <td>0.818483</td>\n",
              "      <td>0.535202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16.0</th>\n",
              "      <td>165.0</td>\n",
              "      <td>0.082837</td>\n",
              "      <td>0.020973</td>\n",
              "      <td>0.080026</td>\n",
              "      <td>0.030628</td>\n",
              "      <td>0.868877</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.928495</td>\n",
              "      <td>0.463018</td>\n",
              "      <td>0.586307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17.0</th>\n",
              "      <td>1339.5</td>\n",
              "      <td>0.034069</td>\n",
              "      <td>0.005725</td>\n",
              "      <td>0.376560</td>\n",
              "      <td>0.064059</td>\n",
              "      <td>0.540126</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.218555</td>\n",
              "      <td>0.659938</td>\n",
              "      <td>0.548621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18.0</th>\n",
              "      <td>153.0</td>\n",
              "      <td>0.693929</td>\n",
              "      <td>0.053121</td>\n",
              "      <td>4.198730</td>\n",
              "      <td>0.018771</td>\n",
              "      <td>0.899400</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.001680</td>\n",
              "      <td>0.734144</td>\n",
              "      <td>0.607351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19.0</th>\n",
              "      <td>622.0</td>\n",
              "      <td>0.358716</td>\n",
              "      <td>0.021738</td>\n",
              "      <td>0.070847</td>\n",
              "      <td>0.479492</td>\n",
              "      <td>0.381012</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.536180</td>\n",
              "      <td>0.651744</td>\n",
              "      <td>0.426944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20.0</th>\n",
              "      <td>130.0</td>\n",
              "      <td>0.795394</td>\n",
              "      <td>0.004153</td>\n",
              "      <td>0.692878</td>\n",
              "      <td>0.056583</td>\n",
              "      <td>0.480324</td>\n",
              "      <td>5.5</td>\n",
              "      <td>2.450475</td>\n",
              "      <td>0.154213</td>\n",
              "      <td>0.420525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21.0</th>\n",
              "      <td>220.5</td>\n",
              "      <td>0.067427</td>\n",
              "      <td>0.005642</td>\n",
              "      <td>0.142211</td>\n",
              "      <td>0.095997</td>\n",
              "      <td>0.261880</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.030150</td>\n",
              "      <td>0.887042</td>\n",
              "      <td>0.564478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22.0</th>\n",
              "      <td>1231.0</td>\n",
              "      <td>0.624999</td>\n",
              "      <td>0.003042</td>\n",
              "      <td>1.114030</td>\n",
              "      <td>0.127632</td>\n",
              "      <td>0.739908</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.082620</td>\n",
              "      <td>0.423445</td>\n",
              "      <td>0.525608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23.0</th>\n",
              "      <td>1112.0</td>\n",
              "      <td>0.060090</td>\n",
              "      <td>0.002159</td>\n",
              "      <td>0.125824</td>\n",
              "      <td>0.059589</td>\n",
              "      <td>0.470073</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.354530</td>\n",
              "      <td>0.234480</td>\n",
              "      <td>0.375921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24.0</th>\n",
              "      <td>1366.0</td>\n",
              "      <td>0.041916</td>\n",
              "      <td>0.004067</td>\n",
              "      <td>0.483038</td>\n",
              "      <td>0.083931</td>\n",
              "      <td>0.888827</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.536365</td>\n",
              "      <td>0.729651</td>\n",
              "      <td>0.527142</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70c11b0f-0f9f-4d98-98c7-a39b6c41f2e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70c11b0f-0f9f-4d98-98c7-a39b6c41f2e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70c11b0f-0f9f-4d98-98c7-a39b6c41f2e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating upper and lower bounds"
      ],
      "metadata": {
        "id": "VYP_WVXN4ZVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "candidates_lower = median_candidates.min()\n",
        "candidates_upper = median_candidates.max()\n",
        "top_20_lower = configs_meta.loc[df_clustering_configs_top20.index].quantile(0.025)\n",
        "top_20_upper = configs_meta.loc[df_clustering_configs_top20.index].quantile(0.975)\n",
        "\n",
        "lower_bound = pd.concat([candidates_lower, top_20_lower], axis=1).min(axis=1)\n",
        "upper_bound = pd.concat([candidates_upper, top_20_upper], axis=1).max(axis=1)\n",
        "\n",
        "upper_bound"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_wQTLBF4Yfe",
        "outputId": "d83e9b01-16ff-463f-a909-9a82c6db8b77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "num_round              5137.000000\n",
              "eta                       0.799657\n",
              "gamma                     3.933173\n",
              "lambda                  435.008500\n",
              "alpha                    17.421280\n",
              "subsample                 0.993467\n",
              "max_depth                15.000000\n",
              "min_child_weight         46.606560\n",
              "colsample_bytree          0.979618\n",
              "colsample_bylevel         0.976192\n",
              "data_id               41157.000000\n",
              "repl                     10.000000\n",
              "timetrain              1373.909200\n",
              "auc                       1.000000\n",
              "task_id              168765.000000\n",
              "cluster                  24.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_bounds(df: pd.DataFrame, lower_bound: pd.Series, upper_bound: pd.Series, columns: List):\n",
        "  '''removes values not within defined bounds'''\n",
        "\n",
        "  # aligning the bounds (which are of type Series) with the dataframe\n",
        "  df_aligned, lower_bound = df.align(lower_bound, join=\"outer\", axis=1)\n",
        "  df_aligned, upper_bound = df.align(upper_bound, join=\"outer\", axis=1)\n",
        "  comp = (df_aligned >= lower_bound) & (df_aligned <= upper_bound)\n",
        "  comp = comp[columns].all(axis=1)\n",
        "  return df[comp]\n",
        "\n",
        "col_names = get_hyperparameter_data_list()\n",
        "df_config_data = apply_bounds(configs_meta, lower_bound, upper_bound, col_names)\n",
        "\n",
        "df_config_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "YZTa1lv67JNt",
        "outputId": "5fd4bdb9-6d35-4dbb-d295-fbfd48281fec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         data_id dataset  repl  num_round       eta     gamma     lambda  \\\n",
              "7          41156     ada     1       1631  0.166113  0.001732   0.903262   \n",
              "8          41156     ada     8         20  0.576736  0.012566  19.786600   \n",
              "12         41156     ada     6         60  0.010230  0.000391   0.000283   \n",
              "17         41156     ada     7        166  0.001851  0.000177   0.228995   \n",
              "20         41156     ada     8         28  0.096808  0.041330   0.151790   \n",
              "...          ...     ...   ...        ...       ...       ...        ...   \n",
              "3386847      181   yeast     3         56  0.027101  0.115404   0.001975   \n",
              "3386848      181   yeast     4        150  0.005761  3.503880  24.006200   \n",
              "3386854      181   yeast     4        218  0.001447  0.002084  25.410900   \n",
              "3386857      181   yeast     2        906  0.002762  0.000225  12.780200   \n",
              "3386865      181   yeast     2        127  0.142853  0.218487   0.066031   \n",
              "\n",
              "             alpha  subsample  max_depth  min_child_weight  colsample_bytree  \\\n",
              "7         0.002555   0.282842          1          0.288864          0.708240   \n",
              "8         0.226136   0.831090         10         24.630600          0.268680   \n",
              "12        0.032876   0.765201          4         35.355700          0.068303   \n",
              "17        0.535231   0.267672          6         24.224900          0.218180   \n",
              "20        0.029790   0.400038          5         16.077100          0.921136   \n",
              "...            ...        ...        ...               ...               ...   \n",
              "3386847   0.038917   0.378640         11         14.760300          0.343482   \n",
              "3386848   1.328130   0.544989          9          2.896090          0.505132   \n",
              "3386854   0.002117   0.989675          8         31.294000          0.839117   \n",
              "3386857   0.089946   0.965303         14         18.786700          0.464231   \n",
              "3386865  13.175400   0.295839         10          4.679090          0.097490   \n",
              "\n",
              "         colsample_bylevel  timetrain       auc  task_id  cluster  \n",
              "7                 0.070882      2.761  0.932474   168767      NaN  \n",
              "8                 0.580386      0.325  0.896607   168767      NaN  \n",
              "12                0.117155      0.350  0.864031   168767      NaN  \n",
              "17                0.696839      1.271  0.859317   168767      NaN  \n",
              "20                0.669970      0.452  0.897574   168767      NaN  \n",
              "...                    ...        ...       ...      ...      ...  \n",
              "3386847           0.478265      0.552  0.827650     2073      NaN  \n",
              "3386848           0.219496      0.722  0.826710     2073      NaN  \n",
              "3386854           0.862304      1.142  0.829504     2073      NaN  \n",
              "3386857           0.942960      4.182  0.782998     2073      NaN  \n",
              "3386865           0.185300      0.609  0.767091     2073      NaN  \n",
              "\n",
              "[921225 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61203f6b-efba-4501-bfac-6b2924bc6d87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_id</th>\n",
              "      <th>dataset</th>\n",
              "      <th>repl</th>\n",
              "      <th>num_round</th>\n",
              "      <th>eta</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "      <th>subsample</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_child_weight</th>\n",
              "      <th>colsample_bytree</th>\n",
              "      <th>colsample_bylevel</th>\n",
              "      <th>timetrain</th>\n",
              "      <th>auc</th>\n",
              "      <th>task_id</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>41156</td>\n",
              "      <td>ada</td>\n",
              "      <td>1</td>\n",
              "      <td>1631</td>\n",
              "      <td>0.166113</td>\n",
              "      <td>0.001732</td>\n",
              "      <td>0.903262</td>\n",
              "      <td>0.002555</td>\n",
              "      <td>0.282842</td>\n",
              "      <td>1</td>\n",
              "      <td>0.288864</td>\n",
              "      <td>0.708240</td>\n",
              "      <td>0.070882</td>\n",
              "      <td>2.761</td>\n",
              "      <td>0.932474</td>\n",
              "      <td>168767</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>41156</td>\n",
              "      <td>ada</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>0.576736</td>\n",
              "      <td>0.012566</td>\n",
              "      <td>19.786600</td>\n",
              "      <td>0.226136</td>\n",
              "      <td>0.831090</td>\n",
              "      <td>10</td>\n",
              "      <td>24.630600</td>\n",
              "      <td>0.268680</td>\n",
              "      <td>0.580386</td>\n",
              "      <td>0.325</td>\n",
              "      <td>0.896607</td>\n",
              "      <td>168767</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>41156</td>\n",
              "      <td>ada</td>\n",
              "      <td>6</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010230</td>\n",
              "      <td>0.000391</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>0.032876</td>\n",
              "      <td>0.765201</td>\n",
              "      <td>4</td>\n",
              "      <td>35.355700</td>\n",
              "      <td>0.068303</td>\n",
              "      <td>0.117155</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.864031</td>\n",
              "      <td>168767</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>41156</td>\n",
              "      <td>ada</td>\n",
              "      <td>7</td>\n",
              "      <td>166</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.228995</td>\n",
              "      <td>0.535231</td>\n",
              "      <td>0.267672</td>\n",
              "      <td>6</td>\n",
              "      <td>24.224900</td>\n",
              "      <td>0.218180</td>\n",
              "      <td>0.696839</td>\n",
              "      <td>1.271</td>\n",
              "      <td>0.859317</td>\n",
              "      <td>168767</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>41156</td>\n",
              "      <td>ada</td>\n",
              "      <td>8</td>\n",
              "      <td>28</td>\n",
              "      <td>0.096808</td>\n",
              "      <td>0.041330</td>\n",
              "      <td>0.151790</td>\n",
              "      <td>0.029790</td>\n",
              "      <td>0.400038</td>\n",
              "      <td>5</td>\n",
              "      <td>16.077100</td>\n",
              "      <td>0.921136</td>\n",
              "      <td>0.669970</td>\n",
              "      <td>0.452</td>\n",
              "      <td>0.897574</td>\n",
              "      <td>168767</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386847</th>\n",
              "      <td>181</td>\n",
              "      <td>yeast</td>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "      <td>0.027101</td>\n",
              "      <td>0.115404</td>\n",
              "      <td>0.001975</td>\n",
              "      <td>0.038917</td>\n",
              "      <td>0.378640</td>\n",
              "      <td>11</td>\n",
              "      <td>14.760300</td>\n",
              "      <td>0.343482</td>\n",
              "      <td>0.478265</td>\n",
              "      <td>0.552</td>\n",
              "      <td>0.827650</td>\n",
              "      <td>2073</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386848</th>\n",
              "      <td>181</td>\n",
              "      <td>yeast</td>\n",
              "      <td>4</td>\n",
              "      <td>150</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>3.503880</td>\n",
              "      <td>24.006200</td>\n",
              "      <td>1.328130</td>\n",
              "      <td>0.544989</td>\n",
              "      <td>9</td>\n",
              "      <td>2.896090</td>\n",
              "      <td>0.505132</td>\n",
              "      <td>0.219496</td>\n",
              "      <td>0.722</td>\n",
              "      <td>0.826710</td>\n",
              "      <td>2073</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386854</th>\n",
              "      <td>181</td>\n",
              "      <td>yeast</td>\n",
              "      <td>4</td>\n",
              "      <td>218</td>\n",
              "      <td>0.001447</td>\n",
              "      <td>0.002084</td>\n",
              "      <td>25.410900</td>\n",
              "      <td>0.002117</td>\n",
              "      <td>0.989675</td>\n",
              "      <td>8</td>\n",
              "      <td>31.294000</td>\n",
              "      <td>0.839117</td>\n",
              "      <td>0.862304</td>\n",
              "      <td>1.142</td>\n",
              "      <td>0.829504</td>\n",
              "      <td>2073</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386857</th>\n",
              "      <td>181</td>\n",
              "      <td>yeast</td>\n",
              "      <td>2</td>\n",
              "      <td>906</td>\n",
              "      <td>0.002762</td>\n",
              "      <td>0.000225</td>\n",
              "      <td>12.780200</td>\n",
              "      <td>0.089946</td>\n",
              "      <td>0.965303</td>\n",
              "      <td>14</td>\n",
              "      <td>18.786700</td>\n",
              "      <td>0.464231</td>\n",
              "      <td>0.942960</td>\n",
              "      <td>4.182</td>\n",
              "      <td>0.782998</td>\n",
              "      <td>2073</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386865</th>\n",
              "      <td>181</td>\n",
              "      <td>yeast</td>\n",
              "      <td>2</td>\n",
              "      <td>127</td>\n",
              "      <td>0.142853</td>\n",
              "      <td>0.218487</td>\n",
              "      <td>0.066031</td>\n",
              "      <td>13.175400</td>\n",
              "      <td>0.295839</td>\n",
              "      <td>10</td>\n",
              "      <td>4.679090</td>\n",
              "      <td>0.097490</td>\n",
              "      <td>0.185300</td>\n",
              "      <td>0.609</td>\n",
              "      <td>0.767091</td>\n",
              "      <td>2073</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>921225 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61203f6b-efba-4501-bfac-6b2924bc6d87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61203f6b-efba-4501-bfac-6b2924bc6d87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61203f6b-efba-4501-bfac-6b2924bc6d87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_auc(data: pd.DataFrame, group_col: str):\n",
        "  '''standardize auc value for each group so as not to bias model'''\n",
        "  auc_means = data.groupby(group_col)[\"auc\"].mean()\n",
        "  auc_std = data.groupby(group_col)[\"auc\"].std()\n",
        "  data[\"auc\"] = data.apply(standardize_row, group_col=group_col, \n",
        "                           task_auc_means=auc_means, task_auc_std=auc_std, axis=1)\n",
        "  return data\n",
        "\n",
        "def standardize_row(row, group_col, task_auc_means, task_auc_std):\n",
        "  '''Applies standardization to row.'''\n",
        "  return (row[\"auc\"] - task_auc_means[row[group_col]]) / task_auc_std[row[group_col]]\n",
        "\n",
        "\n",
        "\n",
        "# drop columns not relevant for our model\n",
        "df_dataset = df_config_data.drop(columns=[\"dataset\", \"repl\", \"task_id\", \"timetrain\", \n",
        "                                          \"colsample_bylevel\", \"cluster\"])\n",
        "\n",
        "# standardize auc per task\n",
        "df_dataset = standardize_auc(df_dataset, \"data_id\")\n",
        "dataset_config_columns = df_dataset.columns.drop([\"data_id\", \"auc\"])\n",
        "\n",
        "tasks_meta.index = tasks_meta[\"data_id\"]\n",
        "tasks_data = tasks_meta.drop(columns=[\"name\", \"version\", \"status\", \"data_id\"])\n",
        "tasks_data = tasks_data.dropna()\n",
        "\n",
        "# create dataset\n",
        "df_dataset = df_dataset.join(tasks_data, on=\"data_id\", how=\"inner\")#.drop(columns=\"data_id\")\n",
        "\n",
        "df_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "RKbt99-4oqpD",
        "outputId": "ccab1dc4-7b27-436d-d630-26dcf9618688"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         data_id  num_round       eta     gamma     lambda      alpha  \\\n",
              "7          41156       1631  0.166113  0.001732   0.903262   0.002555   \n",
              "8          41156         20  0.576736  0.012566  19.786600   0.226136   \n",
              "12         41156         60  0.010230  0.000391   0.000283   0.032876   \n",
              "17         41156        166  0.001851  0.000177   0.228995   0.535231   \n",
              "20         41156         28  0.096808  0.041330   0.151790   0.029790   \n",
              "...          ...        ...       ...       ...        ...        ...   \n",
              "3386847      181         56  0.027101  0.115404   0.001975   0.038917   \n",
              "3386848      181        150  0.005761  3.503880  24.006200   1.328130   \n",
              "3386854      181        218  0.001447  0.002084  25.410900   0.002117   \n",
              "3386857      181        906  0.002762  0.000225  12.780200   0.089946   \n",
              "3386865      181        127  0.142853  0.218487   0.066031  13.175400   \n",
              "\n",
              "         subsample  max_depth  min_child_weight  colsample_bytree  ...  \\\n",
              "7         0.282842          1          0.288864          0.708240  ...   \n",
              "8         0.831090         10         24.630600          0.268680  ...   \n",
              "12        0.765201          4         35.355700          0.068303  ...   \n",
              "17        0.267672          6         24.224900          0.218180  ...   \n",
              "20        0.400038          5         16.077100          0.921136  ...   \n",
              "...            ...        ...               ...               ...  ...   \n",
              "3386847   0.378640         11         14.760300          0.343482  ...   \n",
              "3386848   0.544989          9          2.896090          0.505132  ...   \n",
              "3386854   0.989675          8         31.294000          0.839117  ...   \n",
              "3386857   0.965303         14         18.786700          0.464231  ...   \n",
              "3386865   0.295839         10          4.679090          0.097490  ...   \n",
              "\n",
              "         MajorityClassSize  MaxNominalAttDistinctValues  MinorityClassSize  \\\n",
              "7                     3118                          2.0               1029   \n",
              "8                     3118                          2.0               1029   \n",
              "12                    3118                          2.0               1029   \n",
              "17                    3118                          2.0               1029   \n",
              "20                    3118                          2.0               1029   \n",
              "...                    ...                          ...                ...   \n",
              "3386847                463                         10.0                  5   \n",
              "3386848                463                         10.0                  5   \n",
              "3386854                463                         10.0                  5   \n",
              "3386857                463                         10.0                  5   \n",
              "3386865                463                         10.0                  5   \n",
              "\n",
              "         NumberOfClasses  NumberOfFeatures  NumberOfInstances  \\\n",
              "7                      2                49               4147   \n",
              "8                      2                49               4147   \n",
              "12                     2                49               4147   \n",
              "17                     2                49               4147   \n",
              "20                     2                49               4147   \n",
              "...                  ...               ...                ...   \n",
              "3386847               10                 9               1484   \n",
              "3386848               10                 9               1484   \n",
              "3386854               10                 9               1484   \n",
              "3386857               10                 9               1484   \n",
              "3386865               10                 9               1484   \n",
              "\n",
              "         NumberOfInstancesWithMissingValues  NumberOfMissingValues  \\\n",
              "7                                         0                      0   \n",
              "8                                         0                      0   \n",
              "12                                        0                      0   \n",
              "17                                        0                      0   \n",
              "20                                        0                      0   \n",
              "...                                     ...                    ...   \n",
              "3386847                                   0                      0   \n",
              "3386848                                   0                      0   \n",
              "3386854                                   0                      0   \n",
              "3386857                                   0                      0   \n",
              "3386865                                   0                      0   \n",
              "\n",
              "         NumberOfNumericFeatures  NumberOfSymbolicFeatures  \n",
              "7                             48                         1  \n",
              "8                             48                         1  \n",
              "12                            48                         1  \n",
              "17                            48                         1  \n",
              "20                            48                         1  \n",
              "...                          ...                       ...  \n",
              "3386847                        8                         1  \n",
              "3386848                        8                         1  \n",
              "3386854                        8                         1  \n",
              "3386857                        8                         1  \n",
              "3386865                        8                         1  \n",
              "\n",
              "[901833 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a8a8789-a3b8-474e-b748-100586ab4880\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_id</th>\n",
              "      <th>num_round</th>\n",
              "      <th>eta</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "      <th>subsample</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_child_weight</th>\n",
              "      <th>colsample_bytree</th>\n",
              "      <th>...</th>\n",
              "      <th>MajorityClassSize</th>\n",
              "      <th>MaxNominalAttDistinctValues</th>\n",
              "      <th>MinorityClassSize</th>\n",
              "      <th>NumberOfClasses</th>\n",
              "      <th>NumberOfFeatures</th>\n",
              "      <th>NumberOfInstances</th>\n",
              "      <th>NumberOfInstancesWithMissingValues</th>\n",
              "      <th>NumberOfMissingValues</th>\n",
              "      <th>NumberOfNumericFeatures</th>\n",
              "      <th>NumberOfSymbolicFeatures</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>41156</td>\n",
              "      <td>1631</td>\n",
              "      <td>0.166113</td>\n",
              "      <td>0.001732</td>\n",
              "      <td>0.903262</td>\n",
              "      <td>0.002555</td>\n",
              "      <td>0.282842</td>\n",
              "      <td>1</td>\n",
              "      <td>0.288864</td>\n",
              "      <td>0.708240</td>\n",
              "      <td>...</td>\n",
              "      <td>3118</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1029</td>\n",
              "      <td>2</td>\n",
              "      <td>49</td>\n",
              "      <td>4147</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>41156</td>\n",
              "      <td>20</td>\n",
              "      <td>0.576736</td>\n",
              "      <td>0.012566</td>\n",
              "      <td>19.786600</td>\n",
              "      <td>0.226136</td>\n",
              "      <td>0.831090</td>\n",
              "      <td>10</td>\n",
              "      <td>24.630600</td>\n",
              "      <td>0.268680</td>\n",
              "      <td>...</td>\n",
              "      <td>3118</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1029</td>\n",
              "      <td>2</td>\n",
              "      <td>49</td>\n",
              "      <td>4147</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>41156</td>\n",
              "      <td>60</td>\n",
              "      <td>0.010230</td>\n",
              "      <td>0.000391</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>0.032876</td>\n",
              "      <td>0.765201</td>\n",
              "      <td>4</td>\n",
              "      <td>35.355700</td>\n",
              "      <td>0.068303</td>\n",
              "      <td>...</td>\n",
              "      <td>3118</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1029</td>\n",
              "      <td>2</td>\n",
              "      <td>49</td>\n",
              "      <td>4147</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>41156</td>\n",
              "      <td>166</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.228995</td>\n",
              "      <td>0.535231</td>\n",
              "      <td>0.267672</td>\n",
              "      <td>6</td>\n",
              "      <td>24.224900</td>\n",
              "      <td>0.218180</td>\n",
              "      <td>...</td>\n",
              "      <td>3118</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1029</td>\n",
              "      <td>2</td>\n",
              "      <td>49</td>\n",
              "      <td>4147</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>41156</td>\n",
              "      <td>28</td>\n",
              "      <td>0.096808</td>\n",
              "      <td>0.041330</td>\n",
              "      <td>0.151790</td>\n",
              "      <td>0.029790</td>\n",
              "      <td>0.400038</td>\n",
              "      <td>5</td>\n",
              "      <td>16.077100</td>\n",
              "      <td>0.921136</td>\n",
              "      <td>...</td>\n",
              "      <td>3118</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1029</td>\n",
              "      <td>2</td>\n",
              "      <td>49</td>\n",
              "      <td>4147</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386847</th>\n",
              "      <td>181</td>\n",
              "      <td>56</td>\n",
              "      <td>0.027101</td>\n",
              "      <td>0.115404</td>\n",
              "      <td>0.001975</td>\n",
              "      <td>0.038917</td>\n",
              "      <td>0.378640</td>\n",
              "      <td>11</td>\n",
              "      <td>14.760300</td>\n",
              "      <td>0.343482</td>\n",
              "      <td>...</td>\n",
              "      <td>463</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>1484</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386848</th>\n",
              "      <td>181</td>\n",
              "      <td>150</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>3.503880</td>\n",
              "      <td>24.006200</td>\n",
              "      <td>1.328130</td>\n",
              "      <td>0.544989</td>\n",
              "      <td>9</td>\n",
              "      <td>2.896090</td>\n",
              "      <td>0.505132</td>\n",
              "      <td>...</td>\n",
              "      <td>463</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>1484</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386854</th>\n",
              "      <td>181</td>\n",
              "      <td>218</td>\n",
              "      <td>0.001447</td>\n",
              "      <td>0.002084</td>\n",
              "      <td>25.410900</td>\n",
              "      <td>0.002117</td>\n",
              "      <td>0.989675</td>\n",
              "      <td>8</td>\n",
              "      <td>31.294000</td>\n",
              "      <td>0.839117</td>\n",
              "      <td>...</td>\n",
              "      <td>463</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>1484</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386857</th>\n",
              "      <td>181</td>\n",
              "      <td>906</td>\n",
              "      <td>0.002762</td>\n",
              "      <td>0.000225</td>\n",
              "      <td>12.780200</td>\n",
              "      <td>0.089946</td>\n",
              "      <td>0.965303</td>\n",
              "      <td>14</td>\n",
              "      <td>18.786700</td>\n",
              "      <td>0.464231</td>\n",
              "      <td>...</td>\n",
              "      <td>463</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>1484</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386865</th>\n",
              "      <td>181</td>\n",
              "      <td>127</td>\n",
              "      <td>0.142853</td>\n",
              "      <td>0.218487</td>\n",
              "      <td>0.066031</td>\n",
              "      <td>13.175400</td>\n",
              "      <td>0.295839</td>\n",
              "      <td>10</td>\n",
              "      <td>4.679090</td>\n",
              "      <td>0.097490</td>\n",
              "      <td>...</td>\n",
              "      <td>463</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>1484</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>901833 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a8a8789-a3b8-474e-b748-100586ab4880')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a8a8789-a3b8-474e-b748-100586ab4880 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a8a8789-a3b8-474e-b748-100586ab4880');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "configs_col_order = configs_meta.drop(columns=[\"data_id\", \"auc\"]).columns\n",
        "\n",
        "configs_col_order"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VD3CS6Wlw12",
        "outputId": "355a033e-13ab-40bf-cb34-0d82a7a242e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['dataset', 'repl', 'num_round', 'eta', 'gamma', 'lambda', 'alpha',\n",
              "       'subsample', 'max_depth', 'min_child_weight', 'colsample_bytree',\n",
              "       'colsample_bylevel', 'timetrain', 'task_id', 'cluster'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "X = df_dataset.drop(columns=[\"auc\"])\n",
        "y = df_dataset[\"auc\"]\n",
        "\n",
        "# split 20 percent of groups into test split\n",
        "splitter = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=0)\n",
        "split = splitter.split(df_dataset, groups=df_dataset[\"data_id\"])\n",
        "train_inds, test_inds = next(split)\n",
        "X = X.drop(columns=[\"data_id\"])\n",
        "dataset_columns = X.columns\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "X_train, X_test, y_train, y_test = X[train_inds], X[test_inds], y[train_inds], y[test_inds]"
      ],
      "metadata": {
        "id": "Qf7qWUaCtbCm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CorkkcUmwYmy",
        "outputId": "d6cc273d-9b3d-4a56-af40-39daf2189ae5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(186890, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k01MEjPMHKT",
        "outputId": "6206240b-c72b-411d-cfae-b116a3900918"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(714943, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest as EPM. Hyperparameter tuning:"
      ],
      "metadata": {
        "id": "s3wYqTKrXgtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import ParameterSampler\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "rf = RandomForestRegressor(random_state=0, bootstrap=True)\n",
        "\n",
        "#parameter space for random search\n",
        "hp_space = dict(n_estimators=[10,25,50,75],\n",
        "                max_depth=randint(3,10),\n",
        "                min_samples_split=randint(10,100),\n",
        "                min_samples_leaf=randint(5,50),\n",
        "                max_samples=uniform(loc=0.33, scale=0.66))\n",
        "\n",
        "#sample ten configurations\n",
        "hp_samples = ParameterSampler(hp_space, n_iter=10, random_state=0)\n",
        "\n",
        "# test configurations and save best one\n",
        "scores = []\n",
        "best_score = 0\n",
        "best_params = {}\n",
        "\n",
        "for params in hp_samples:\n",
        "  print(params)\n",
        "  rf.set_params(**params)\n",
        "  rf.fit(X_train, y_train)\n",
        "  score = rf.score(X_test, y_test)\n",
        "  scores.append(score)\n",
        "  print(\"Score: \" + str(score))\n",
        "  if score > best_score:\n",
        "    best_score = score\n",
        "    best_params = params\n",
        "    print(\"New best params:\" + str(params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftEIl296XfxZ",
        "outputId": "4856cb05-ca46-4d83-dd8f-8dab4cf0d977"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 7, 'max_samples': 0.7212774480285121, 'min_samples_leaf': 5, 'min_samples_split': 77, 'n_estimators': 75}\n",
            "Score: 0.2848538842527947\n",
            "New best params:{'max_depth': 7, 'max_samples': 0.7212774480285121, 'min_samples_leaf': 5, 'min_samples_split': 77, 'n_estimators': 75}\n",
            "{'max_depth': 6, 'max_samples': 0.8891861475975229, 'min_samples_leaf': 24, 'min_samples_split': 31, 'n_estimators': 50}\n",
            "Score: 0.2765009449037944\n",
            "{'max_depth': 7, 'max_samples': 0.5263728403193517, 'min_samples_leaf': 29, 'min_samples_split': 98, 'n_estimators': 10}\n",
            "Score: 0.2916812939287169\n",
            "New best params:{'max_depth': 7, 'max_samples': 0.5263728403193517, 'min_samples_leaf': 29, 'min_samples_split': 98, 'n_estimators': 10}\n",
            "{'max_depth': 5, 'max_samples': 0.6452589774320909, 'min_samples_leaf': 44, 'min_samples_split': 97, 'n_estimators': 50}\n",
            "Score: 0.24848941807235958\n",
            "{'max_depth': 3, 'max_samples': 0.5892379654265476, 'min_samples_leaf': 30, 'min_samples_split': 87, 'n_estimators': 10}\n",
            "Score: 0.1621704218979373\n",
            "{'max_depth': 4, 'max_samples': 0.7577934355537902, 'min_samples_leaf': 21, 'min_samples_split': 79, 'n_estimators': 50}\n",
            "Score: 0.21683054296553084\n",
            "{'max_depth': 3, 'max_samples': 0.9758881058736242, 'min_samples_leaf': 29, 'min_samples_split': 59, 'n_estimators': 75}\n",
            "Score: 0.16272510018473307\n",
            "{'max_depth': 8, 'max_samples': 0.8451492563490606, 'min_samples_leaf': 19, 'min_samples_split': 49, 'n_estimators': 10}\n",
            "Score: 0.2977709567936928\n",
            "New best params:{'max_depth': 8, 'max_samples': 0.8451492563490606, 'min_samples_leaf': 19, 'min_samples_split': 49, 'n_estimators': 10}\n",
            "{'max_depth': 4, 'max_samples': 0.42461316968997065, 'min_samples_leaf': 37, 'min_samples_split': 41, 'n_estimators': 50}\n",
            "Score: 0.21762140532726415\n",
            "{'max_depth': 7, 'max_samples': 0.6425762767687939, 'min_samples_leaf': 16, 'min_samples_split': 65, 'n_estimators': 10}\n",
            "Score: 0.28079830951747187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConfigRecommender:\n",
        "\n",
        "  def __init__(self, epm, candidates: pd.DataFrame):\n",
        "    self.epm = epm\n",
        "    self.candidates = candidates\n",
        "\n",
        "  def _score_candidate(self, row, column_list, meta_features_array):\n",
        "    '''scores candidate based on provided metafeatures'''\n",
        "    config_array = row[column_list].values\n",
        "    epm_features = np.concatenate((config_array, meta_features_array)).reshape(1,-1)\n",
        "    score = self.epm.predict(epm_features)[0]\n",
        "    return score\n",
        "\n",
        "  def create_config(self, meta_features):\n",
        "    '''scores all configs and returns candidate with highest score'''\n",
        "\n",
        "    keys_to_remove = [\"name\", \"status\", \"data_id\"]\n",
        "    for key in keys_to_remove:\n",
        "      if key in meta_features:\n",
        "        del meta_features[key]\n",
        "\n",
        "    #scoring all candidates\n",
        "    metafeatures_array = np.array(list(meta_features.values()))\n",
        "    self.candidates[\"score\"] = self.candidates.apply(self._score_candidate, axis=1, \n",
        "                                           column_list=dataset_config_columns, \n",
        "                                           meta_features_array=metafeatures_array)\n",
        "    # best candidate\n",
        "    max_score = self.candidates[\"score\"].max()\n",
        "    best_configs = self.candidates[self.candidates[\"score\"] == max_score]\n",
        "    config_select = best_configs.sample(1, random_state=0)\n",
        "\n",
        "    #turn best candidate into config in dictionary\n",
        "    config_recommendation = {}\n",
        "    hyperparam_keys = get_hyperparameter_list()\n",
        "\n",
        "    for key in hyperparam_keys:\n",
        "      if key == \"colsample_bylevel\":\n",
        "        config_recommendation[\"colsample_bylevel\"] = self.candidates[\"colsample_bylevel\"].mean()\n",
        "        continue\n",
        "      if key == \"n_estimators\":\n",
        "        config_recommendation[\"n_estimators\"] = config_select[\"num_round\"].values[0]\n",
        "        continue\n",
        "      config_recommendation[key] = config_select[key].values[0]\n",
        "\n",
        "    return config_recommendation\n",
        "\n",
        "crec = ConfigRecommender(rf_epm, median_candidates)"
      ],
      "metadata": {
        "id": "4fQIKaz-Aqxn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_auc = {}\n",
        "results_traintime = {}\n",
        "\n",
        "for task_id in test_ids:\n",
        "  seed=0\n",
        "  print(f\"Task ID: {task_id}\")\n",
        "  # create the XGBoost interface\n",
        "  objective = XGBoostTest(task_id, meta_feature_names, seed)\n",
        "  # extract meta features\n",
        "  meta_features = objective.meta_features\n",
        "  print(f\"The meta features of task ID {task_id} are:\")\n",
        "  print(meta_features)\n",
        "  # pass the meta feature to your model for a configuration\n",
        "  config = crec.create_config(meta_features)\n",
        "  # evaluate the config\n",
        "  print(f\"The recommended config for task ID {task_id}:\")\n",
        "  print(config)\n",
        "  auc, traintime = objective.evaluate(config)\n",
        "  print(f\"The recommended config scored an AUC of {auc} in {traintime}s on task ID {task_id}.\")\n",
        "  # evaluate the default config for the baseline\n",
        "  base_auc, base_traintime = objective.evaluate(default_config)\n",
        "  print(f\"The default config scored an AUC of {base_auc} in {base_traintime}s on task ID {task_id}.\")\n",
        "  results_auc[task_id] = (auc, base_auc)\n",
        "  results_traintime[task_id] = (traintime, base_traintime)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "psktoBA1WPlQ",
        "outputId": "110f6cb7-4288-4673-85fc-39b949660679"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task ID: 16\n",
            "The meta features of task ID 16 are:\n",
            "{'name': 'mfeat-karhunen', 'status': 'active', 'MajorityClassSize': 200.0, 'MaxNominalAttDistinctValues': 10.0, 'MinorityClassSize': 200.0, 'NumberOfClasses': 10.0, 'NumberOfFeatures': 65.0, 'NumberOfInstances': 2000.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 64.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 16}\n",
            "The recommended config for task ID 16:\n",
            "{'n_estimators': 55, 'eta': 0.452886, 'subsample': 0.874718, 'max_depth': 7, 'min_child_weight': 3.21882, 'colsample_bytree': 0.9249795000000001, 'colsample_bylevel': 0.5329972399999999, 'lambda': 0.0917794, 'alpha': 0.4297955, 'gamma': 0.021100149999999998}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.9979166666666666 in 0.9105732440948486s on task ID 16.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.99725 in 17.47377610206604s on task ID 16.\n",
            "Task ID: 22\n",
            "The meta features of task ID 22 are:\n",
            "{'name': 'mfeat-zernike', 'status': 'active', 'MajorityClassSize': 200.0, 'MaxNominalAttDistinctValues': 10.0, 'MinorityClassSize': 200.0, 'NumberOfClasses': 10.0, 'NumberOfFeatures': 48.0, 'NumberOfInstances': 2000.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 47.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 22}\n",
            "The recommended config for task ID 22:\n",
            "{'n_estimators': 55, 'eta': 0.452886, 'subsample': 0.874718, 'max_depth': 7, 'min_child_weight': 3.21882, 'colsample_bytree': 0.9249795000000001, 'colsample_bylevel': 0.5329972399999999, 'lambda': 0.0917794, 'alpha': 0.4297955, 'gamma': 0.021100149999999998}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.9627777777777778 in 0.7782614231109619s on task ID 22.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9724999999999999 in 16.963614463806152s on task ID 22.\n",
            "Task ID: 31\n",
            "The meta features of task ID 31 are:\n",
            "{'name': 'credit-g', 'status': 'active', 'MajorityClassSize': 700.0, 'MaxNominalAttDistinctValues': 10.0, 'MinorityClassSize': 300.0, 'NumberOfClasses': 2.0, 'NumberOfFeatures': 21.0, 'NumberOfInstances': 1000.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 7.0, 'NumberOfSymbolicFeatures': 14.0, 'data_id': 31}\n",
            "The recommended config for task ID 31:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.7985714285714286 in 0.3676266670227051s on task ID 31.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.8414285714285714 in 1.9916462898254395s on task ID 31.\n",
            "Task ID: 2074\n",
            "The meta features of task ID 2074 are:\n",
            "{'name': 'satimage', 'status': 'active', 'MajorityClassSize': 1531.0, 'MaxNominalAttDistinctValues': 6.0, 'MinorityClassSize': 625.0, 'NumberOfClasses': 6.0, 'NumberOfFeatures': 37.0, 'NumberOfInstances': 6430.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 36.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 182}\n",
            "The recommended config for task ID 2074:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.992587149326091 in 0.8462677001953125s on task ID 2074.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9894436138432651 in 15.36357569694519s on task ID 2074.\n",
            "Task ID: 2079\n",
            "The meta features of task ID 2079 are:\n",
            "{'name': 'eucalyptus', 'status': 'active', 'MajorityClassSize': 214.0, 'MaxNominalAttDistinctValues': 27.0, 'MinorityClassSize': 105.0, 'NumberOfClasses': 5.0, 'NumberOfFeatures': 20.0, 'NumberOfInstances': 736.0, 'NumberOfInstancesWithMissingValues': 95.0, 'NumberOfMissingValues': 448.0, 'NumberOfNumericFeatures': 14.0, 'NumberOfSymbolicFeatures': 6.0, 'data_id': 188}\n",
            "The recommended config for task ID 2079:\n",
            "{'n_estimators': 55, 'eta': 0.452886, 'subsample': 0.874718, 'max_depth': 7, 'min_child_weight': 3.21882, 'colsample_bytree': 0.9249795000000001, 'colsample_bylevel': 0.5329972399999999, 'lambda': 0.0917794, 'alpha': 0.4297955, 'gamma': 0.021100149999999998}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.9201786893211267 in 0.7098307609558105s on task ID 2079.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9164284975257756 in 8.26139521598816s on task ID 2079.\n",
            "Task ID: 3493\n",
            "The meta features of task ID 3493 are:\n",
            "{'name': 'monks-problems-2', 'status': 'active', 'MajorityClassSize': 395.0, 'MaxNominalAttDistinctValues': 4.0, 'MinorityClassSize': 206.0, 'NumberOfClasses': 2.0, 'NumberOfFeatures': 7.0, 'NumberOfInstances': 601.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 0.0, 'NumberOfSymbolicFeatures': 7.0, 'data_id': 334}\n",
            "The recommended config for task ID 3493:\n",
            "{'n_estimators': 55, 'eta': 0.452886, 'subsample': 0.874718, 'max_depth': 7, 'min_child_weight': 3.21882, 'colsample_bytree': 0.9249795000000001, 'colsample_bylevel': 0.5329972399999999, 'lambda': 0.0917794, 'alpha': 0.4297955, 'gamma': 0.021100149999999998}\n",
            "The recommended config scored an AUC of 0.9940476190476191 in 0.08740997314453125s on task ID 3493.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9761904761904763 in 0.8765239715576172s on task ID 3493.\n",
            "Task ID: 3907\n",
            "The meta features of task ID 3907 are:\n",
            "{'name': 'mc1', 'status': 'active', 'MajorityClassSize': 9398.0, 'MaxNominalAttDistinctValues': 2.0, 'MinorityClassSize': 68.0, 'NumberOfClasses': 2.0, 'NumberOfFeatures': 39.0, 'NumberOfInstances': 9466.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 38.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 1056}\n",
            "The recommended config for task ID 3907:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.9869300911854104 in 0.2914586067199707s on task ID 3907.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9869300911854103 in 1.4911251068115234s on task ID 3907.\n",
            "Task ID: 3913\n",
            "The meta features of task ID 3913 are:\n",
            "{'name': 'kc2', 'status': 'active', 'MajorityClassSize': 415.0, 'MaxNominalAttDistinctValues': 2.0, 'MinorityClassSize': 107.0, 'NumberOfClasses': 2.0, 'NumberOfFeatures': 22.0, 'NumberOfInstances': 522.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 21.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 1063}\n",
            "The recommended config for task ID 3913:\n",
            "{'n_estimators': 55, 'eta': 0.452886, 'subsample': 0.874718, 'max_depth': 7, 'min_child_weight': 3.21882, 'colsample_bytree': 0.9249795000000001, 'colsample_bylevel': 0.5329972399999999, 'lambda': 0.0917794, 'alpha': 0.4297955, 'gamma': 0.021100149999999998}\n",
            "The recommended config scored an AUC of 0.8571428571428572 in 0.1004645824432373s on task ID 3913.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.8874458874458874 in 0.8363502025604248s on task ID 3913.\n",
            "Task ID: 9950\n",
            "The meta features of task ID 9950 are:\n",
            "{'name': 'micro-mass', 'status': 'active', 'MajorityClassSize': 60.0, 'MaxNominalAttDistinctValues': 20.0, 'MinorityClassSize': 11.0, 'NumberOfClasses': 20.0, 'NumberOfFeatures': 1301.0, 'NumberOfInstances': 571.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 1300.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 1515}\n",
            "The recommended config for task ID 9950:\n",
            "{'n_estimators': 173, 'eta': 0.0414371, 'subsample': 0.826596, 'max_depth': 14, 'min_child_weight': 2.45042, 'colsample_bytree': 0.760872, 'colsample_bylevel': 0.5329972399999999, 'lambda': 0.197935, 'alpha': 0.0381361, 'gamma': 0.0268966}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.9960603516853517 in 7.601161241531372s on task ID 9950.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9969357263107262 in 41.47692513465881s on task ID 9950.\n",
            "Task ID: 9952\n",
            "The meta features of task ID 9952 are:\n",
            "{'name': 'phoneme', 'status': 'active', 'MajorityClassSize': 3818.0, 'MaxNominalAttDistinctValues': 2.0, 'MinorityClassSize': 1586.0, 'NumberOfClasses': 2.0, 'NumberOfFeatures': 6.0, 'NumberOfInstances': 5404.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 5.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 1489}\n",
            "The recommended config for task ID 9952:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.9480885113108762 in 0.42847466468811035s on task ID 9952.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9506733840429386 in 3.0572776794433594s on task ID 9952.\n",
            "Task ID: 9971\n",
            "The meta features of task ID 9971 are:\n",
            "{'name': 'ilpd', 'status': 'active', 'MajorityClassSize': 416.0, 'MaxNominalAttDistinctValues': 2.0, 'MinorityClassSize': 167.0, 'NumberOfClasses': 2.0, 'NumberOfFeatures': 11.0, 'NumberOfInstances': 583.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 9.0, 'NumberOfSymbolicFeatures': 2.0, 'data_id': 1480}\n",
            "The recommended config for task ID 9971:\n",
            "{'n_estimators': 55, 'eta': 0.452886, 'subsample': 0.874718, 'max_depth': 7, 'min_child_weight': 3.21882, 'colsample_bytree': 0.9249795000000001, 'colsample_bylevel': 0.5329972399999999, 'lambda': 0.0917794, 'alpha': 0.4297955, 'gamma': 0.021100149999999998}\n",
            "The recommended config scored an AUC of 0.7619047619047619 in 0.10547399520874023s on task ID 9971.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.680672268907563 in 0.9644536972045898s on task ID 9971.\n",
            "Task ID: 10106\n",
            "The meta features of task ID 10106 are:\n",
            "{'name': 'CreditCardSubset', 'status': 'active', 'MajorityClassSize': 14217.0, 'MaxNominalAttDistinctValues': 2.0, 'MinorityClassSize': 23.0, 'NumberOfClasses': 2.0, 'NumberOfFeatures': 31.0, 'NumberOfInstances': 14240.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 30.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 4154}\n",
            "The recommended config for task ID 10106:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n",
            "The recommended config scored an AUC of 0.9992967651195499 in 0.13700318336486816s on task ID 10106.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9992967651195499 in 0.7232687473297119s on task ID 10106.\n",
            "Task ID: 14954\n",
            "The meta features of task ID 14954 are:\n",
            "{'name': 'cylinder-bands', 'status': 'active', 'MajorityClassSize': 312.0, 'MaxNominalAttDistinctValues': 71.0, 'MinorityClassSize': 228.0, 'NumberOfClasses': 2.0, 'NumberOfFeatures': 40.0, 'NumberOfInstances': 540.0, 'NumberOfInstancesWithMissingValues': 263.0, 'NumberOfMissingValues': 999.0, 'NumberOfNumericFeatures': 18.0, 'NumberOfSymbolicFeatures': 22.0, 'data_id': 6332}\n",
            "The recommended config for task ID 14954:\n",
            "{'n_estimators': 55, 'eta': 0.452886, 'subsample': 0.874718, 'max_depth': 7, 'min_child_weight': 3.21882, 'colsample_bytree': 0.9249795000000001, 'colsample_bylevel': 0.5329972399999999, 'lambda': 0.0917794, 'alpha': 0.4297955, 'gamma': 0.021100149999999998}\n",
            "The recommended config scored an AUC of 0.9046283309957924 in 0.103485107421875s on task ID 14954.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.903225806451613 in 1.8714089393615723s on task ID 14954.\n",
            "Task ID: 14970\n",
            "The meta features of task ID 14970 are:\n",
            "{'name': 'har', 'status': 'active', 'MajorityClassSize': 1944.0, 'MaxNominalAttDistinctValues': 6.0, 'MinorityClassSize': 1406.0, 'NumberOfClasses': 6.0, 'NumberOfFeatures': 562.0, 'NumberOfInstances': 10299.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 561.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 1478}\n",
            "The recommended config for task ID 14970:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.9999438490640666 in 3.2436912059783936s on task ID 14970.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9998465606185354 in 82.50906777381897s on task ID 14970.\n",
            "Task ID: 146212\n",
            "The meta features of task ID 146212 are:\n",
            "{'name': 'shuttle', 'status': 'active', 'MajorityClassSize': 45586.0, 'MaxNominalAttDistinctValues': 7.0, 'MinorityClassSize': 10.0, 'NumberOfClasses': 7.0, 'NumberOfFeatures': 10.0, 'NumberOfInstances': 58000.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 9.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 40685}\n",
            "The recommended config for task ID 146212:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.9999999747500462 in 0.8447234630584717s on task ID 146212.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.999998445885652 in 3.5221197605133057s on task ID 146212.\n",
            "Task ID: 146825\n",
            "The meta features of task ID 146825 are:\n",
            "{'name': 'Fashion-MNIST', 'status': 'active', 'MajorityClassSize': 7000.0, 'MaxNominalAttDistinctValues': 10.0, 'MinorityClassSize': 7000.0, 'NumberOfClasses': 10.0, 'NumberOfFeatures': 785.0, 'NumberOfInstances': 70000.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 784.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 40996}\n",
            "The recommended config for task ID 146825:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.9928760317460318 in 38.33784294128418s on task ID 146825.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9923536507936509 in 844.6401925086975s on task ID 146825.\n",
            "Task ID: 167119\n",
            "The meta features of task ID 167119 are:\n",
            "{'name': 'jungle_chess_2pcs_raw_endgame_complete', 'status': 'active', 'MajorityClassSize': 23062.0, 'MaxNominalAttDistinctValues': 3.0, 'MinorityClassSize': 4335.0, 'NumberOfClasses': 3.0, 'NumberOfFeatures': 7.0, 'NumberOfInstances': 44819.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 6.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 41027}\n",
            "The recommended config for task ID 167119:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.97597096589524 in 2.8454227447509766s on task ID 167119.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9692279724218947 in 47.10283923149109s on task ID 167119.\n",
            "Task ID: 167125\n",
            "The meta features of task ID 167125 are:\n",
            "{'name': 'Internet-Advertisements', 'status': 'active', 'MajorityClassSize': 2820.0, 'MaxNominalAttDistinctValues': 2.0, 'MinorityClassSize': 459.0, 'NumberOfClasses': 2.0, 'NumberOfFeatures': 1559.0, 'NumberOfInstances': 3279.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 3.0, 'NumberOfSymbolicFeatures': 1556.0, 'data_id': 40978}\n",
            "The recommended config for task ID 167125:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.9540548874498921 in 1.583632469177246s on task ID 167125.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.9670444033302498 in 21.888904094696045s on task ID 167125.\n",
            "Task ID: 168332\n",
            "The meta features of task ID 168332 are:\n",
            "{'name': 'robert', 'status': 'active', 'MajorityClassSize': 1043.0, 'MaxNominalAttDistinctValues': 10.0, 'MinorityClassSize': 958.0, 'NumberOfClasses': 10.0, 'NumberOfFeatures': 7201.0, 'NumberOfInstances': 10000.0, 'NumberOfInstancesWithMissingValues': 0.0, 'NumberOfMissingValues': 0.0, 'NumberOfNumericFeatures': 7200.0, 'NumberOfSymbolicFeatures': 1.0, 'data_id': 41165}\n",
            "The recommended config for task ID 168332:\n",
            "{'n_estimators': 153, 'eta': 0.693929, 'subsample': 0.8994, 'max_depth': 13, 'min_child_weight': 3.00168, 'colsample_bytree': 0.734144, 'colsample_bylevel': 0.5329972399999999, 'lambda': 4.19873, 'alpha': 0.0187712, 'gamma': 0.0531213}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recommended config scored an AUC of 0.860660246346602 in 98.22577261924744s on task ID 168332.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The default config scored an AUC of 0.8771189955680253 in 4291.63919377327s on task ID 168332.\n",
            "Task ID: 168336\n",
            "The meta features of task ID 168336 are:\n",
            "{'name': 'kick', 'status': 'active', 'MajorityClassSize': 64007.0, 'MinorityClassSize': 8976.0, 'NumberOfClasses': 2.0, 'NumberOfFeatures': 33.0, 'NumberOfInstances': 72983.0, 'NumberOfInstancesWithMissingValues': 69709.0, 'NumberOfMissingValues': 149271.0, 'NumberOfNumericFeatures': 14.0, 'NumberOfSymbolicFeatures': 19.0, 'data_id': 41162}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-34005b6b7fcd>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# pass the meta feature to your model for a configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;31m# evaluate the config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The recommended config for task ID {task_id}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-8c16f359598f>\u001b[0m in \u001b[0;36mcreate_config\u001b[0;34m(self, meta_features)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmetafeatures_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     self.candidates[\"score\"] = self.candidates.apply(self._score_candidate, axis=1, \n\u001b[0m\u001b[1;32m     27\u001b[0m                                            \u001b[0mcolumn_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_config_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                            meta_features_array=metafeatures_array)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-8c16f359598f>\u001b[0m in \u001b[0;36m_score_candidate\u001b[0;34m(self, row, column_list, meta_features_array)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepm_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_features_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print(epm_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepm_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    600\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    601\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 18 features, but RandomForestRegressor is expecting 19 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VwqNnEaKcOz",
        "outputId": "71f11082-edf1-490f-f927-797d43e4ccab"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{16: (0.9979166666666666, 0.99725),\n",
              " 22: (0.9627777777777778, 0.9724999999999999),\n",
              " 31: (0.7985714285714286, 0.8414285714285714),\n",
              " 2074: (0.992587149326091, 0.9894436138432651),\n",
              " 2079: (0.9201786893211267, 0.9164284975257756),\n",
              " 3493: (0.9940476190476191, 0.9761904761904763),\n",
              " 3907: (0.9869300911854104, 0.9869300911854103),\n",
              " 3913: (0.8571428571428572, 0.8874458874458874),\n",
              " 9950: (0.9960603516853517, 0.9969357263107262),\n",
              " 9952: (0.9480885113108762, 0.9506733840429386),\n",
              " 9971: (0.7619047619047619, 0.680672268907563),\n",
              " 10106: (0.9992967651195499, 0.9992967651195499),\n",
              " 14954: (0.9046283309957924, 0.903225806451613),\n",
              " 14970: (0.9999438490640666, 0.9998465606185354),\n",
              " 146212: (0.9999999747500462, 0.999998445885652),\n",
              " 146825: (0.9928760317460318, 0.9923536507936509),\n",
              " 167119: (0.97597096589524, 0.9692279724218947),\n",
              " 167125: (0.9540548874498921, 0.9670444033302498),\n",
              " 168332: (0.860660246346602, 0.8771189955680253)}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_auc = pd.DataFrame(results_auc)\n",
        "\n",
        "df_auc.max(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrpxKH7HpmMY",
        "outputId": "6fc151aa-51b7-4745-dadd-003c78e9ea39"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.000000\n",
              "1    0.999998\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_traintime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPqN5Qwkm7iJ",
        "outputId": "c85bdb93-700d-403e-9e55-00b7882583f4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{16: (0.9105732440948486, 17.47377610206604),\n",
              " 22: (0.7782614231109619, 16.963614463806152),\n",
              " 31: (0.3676266670227051, 1.9916462898254395),\n",
              " 2074: (0.8462677001953125, 15.36357569694519),\n",
              " 2079: (0.7098307609558105, 8.26139521598816),\n",
              " 3493: (0.08740997314453125, 0.8765239715576172),\n",
              " 3907: (0.2914586067199707, 1.4911251068115234),\n",
              " 3913: (0.1004645824432373, 0.8363502025604248),\n",
              " 9950: (7.601161241531372, 41.47692513465881),\n",
              " 9952: (0.42847466468811035, 3.0572776794433594),\n",
              " 9971: (0.10547399520874023, 0.9644536972045898),\n",
              " 10106: (0.13700318336486816, 0.7232687473297119),\n",
              " 14954: (0.103485107421875, 1.8714089393615723),\n",
              " 14970: (3.2436912059783936, 82.50906777381897),\n",
              " 146212: (0.8447234630584717, 3.5221197605133057),\n",
              " 146825: (38.33784294128418, 844.6401925086975),\n",
              " 167119: (2.8454227447509766, 47.10283923149109),\n",
              " 167125: (1.583632469177246, 21.888904094696045),\n",
              " 168332: (98.22577261924744, 4291.63919377327)}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_traintime = pd.DataFrame(results_traintime)\n",
        "\n",
        "df_traintime.max(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-bjrgd0qkbV",
        "outputId": "2e15c43c-292a-4828-a9b4-7c4fc6ffbe69"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      98.225773\n",
              "1    4291.639194\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}